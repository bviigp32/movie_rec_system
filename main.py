import pickle
import json
import redis
import pandas as pd
from fastapi import FastAPI, HTTPException, Depends
from sqlalchemy.orm import Session
from database import get_db, engine
import models

# 1. ì¸í”„ë¼ ì—°ê²° ì„¤ì •
# Redis ì—°ê²° (Docker ì»¨í…Œì´ë„ˆ ì´ë¦„ì´ 'movie-redis'ê°€ ì•„ë‹ˆë¼ ë¡œì»¬í˜¸ìŠ¤íŠ¸ë¡œ ì ‘ì†)
# ì´ìœ : uvicornì„ ë‚´ ì»´í“¨í„°ì—ì„œ ì‹¤í–‰í•˜ë‹ˆê¹Œ localhost:6379ë¡œ ë¶™ì–´ì•¼ í•¨
rd = redis.Redis(host='localhost', port=6379, db=0)

# 2. í•™ìŠµëœ AI ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
# ì„œë²„ ì¼¤ ë•Œ í•œ ë²ˆë§Œ ë¡œë”© (ë©”ëª¨ë¦¬ ì ˆì•½)
MODEL_PATH = "recommendation_model.pkl"
print("AI ëª¨ë¸ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤...")
with open(MODEL_PATH, 'rb') as f:
    model = pickle.load(f)
print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

# 3. ì˜í™” ëª©ë¡ ë¯¸ë¦¬ ë¡œë”© (ë§¤ë²ˆ DB ê°€ë©´ ëŠë¦¬ë‹ˆê¹Œ)
print("ì˜í™” ëª©ë¡ì„ ìºì‹± ì¤‘ì…ë‹ˆë‹¤...")
all_movie_ids = pd.read_sql("SELECT id FROM movies", engine)['id'].tolist()
print(f"ì´ {len(all_movie_ids)}ê°œì˜ ì˜í™” ID ë¡œë”© ì™„ë£Œ.")

app = FastAPI()

@app.get("/")
def read_root():
    return {"message": "Netflix Lite Recommendation API"}

@app.get("/recommend/{user_id}")
def get_recommendations(user_id: int, db: Session = Depends(get_db)):
    """
    íŠ¹ì • ìœ ì €(user_id)ì—ê²Œ 'ì•„ì§ ì•ˆ ë³¸ ì˜í™”' ì¤‘ 10ê°œë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.
    """
    cache_key = f"rec:{user_id}"

    # 1. Redis ìºì‹œ í™•ì¸
    cached_data = rd.get(cache_key)
    if cached_data:
        print(f"âš¡ [Cache Hit] ìœ ì € {user_id}ì˜ ì¶”ì²œ ëª©ë¡ì„ Redisì—ì„œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
        return json.loads(cached_data)

    print(f"ğŸ¢ [Cache Miss] AI ëª¨ë¸ì´ ìœ ì € {user_id}ì˜ ì·¨í–¥ì„ ë¶„ì„ ì¤‘...")

    # --- [ì—…ê·¸ë ˆì´ë“œ ëœ ë¡œì§ ì‹œì‘] ---
    
    # 2. ìœ ì €ê°€ ì´ë¯¸ ë³¸(í‰ì ì„ ë‚¨ê¸´) ì˜í™” ID ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    # DB ì¿¼ë¦¬: SELECT movie_id FROM ratings WHERE user_id = ...
    watched_list = db.query(models.Rating.movie_id).filter(models.Rating.user_id == user_id).all()
    # ê°€ì ¸ì˜¨ ë¦¬ìŠ¤íŠ¸ [(1,), (50,), (100,)] ë¥¼ ì§‘í•© {1, 50, 100} ìœ¼ë¡œ ë³€í™˜
    watched_movie_ids = {m[0] for m in watched_list}

    # 3. ì•ˆ ë³¸ ì˜í™”ë§Œ ë‚¨ê¸°ê¸° (ì°¨ì§‘í•© ì—°ì‚°)
    # ì „ì²´ ì˜í™”(set) - ë³¸ ì˜í™”(set) = ì•ˆ ë³¸ ì˜í™”
    all_movie_set = set(all_movie_ids)
    unseen_movie_ids = all_movie_set - watched_movie_ids
    
    print(f"ğŸ” ì „ì²´ {len(all_movie_ids)}ê°œ ì¤‘ ìœ ì €ê°€ ì•ˆ ë³¸ {len(unseen_movie_ids)}ê°œ ì˜í™”ë§Œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

    # 4. ì•ˆ ë³¸ ì˜í™”ì— ëŒ€í•´ì„œë§Œ ì˜ˆì¸¡ ìˆ˜í–‰
    predictions = []
    for movie_id in unseen_movie_ids:
        pred = model.predict(user_id, movie_id)
        predictions.append((movie_id, pred.est))
    
    # --- [ì—…ê·¸ë ˆì´ë“œ ëœ ë¡œì§ ë] ---

    # 5. ìƒìœ„ 10ê°œ ì¶”ì¶œ (ë‚˜ë¨¸ì§€ëŠ” ë™ì¼)
    top_10 = sorted(predictions, key=lambda x: x[1], reverse=True)[:10]
    
    top_movie_ids = [m[0] for m in top_10]
    movies = db.query(models.Movie).filter(models.Movie.id.in_(top_movie_ids)).all()
    
    result = []
    for m in movies:
        score = next(item[1] for item in top_10 if item[0] == m.id)
        result.append({
            "movie_id": m.id,
            "title": m.title,
            "genres": m.genres,
            "predicted_score": round(score, 2)
        })

    rd.setex(cache_key, 3600, json.dumps(result))
    
    return result